import os

BOT_NAME = "bookScrape"

SPIDER_MODULES = ["bookScrape.spiders"]
NEWSPIDER_MODULE = "bookScrape.spiders"

ADDONS = {}

ROBOTSTXT_OBEY = False

CONCURRENT_REQUESTS = 64
CONCURRENT_REQUESTS_PER_DOMAIN = 36
DOWNLOAD_DELAY = 0
AUTOTHROTTLE_ENABLED = False

RETRY_ENABLED = True
RETRY_TIMES = 2
DOWNLOAD_TIMEOUT = 15

COOKIES_ENABLED = False
TELNETCONSOLE_ENABLED = False

SPIDER_MIDDLEWARES = {}
DOWNLOADER_MIDDLEWARES = {
    "bookScrape.middlewares.ScrapeOpsHeadersMiddleware": 300
}

EXTENSIONS = {}

ITEM_PIPELINES = {}

AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 2
AUTOTHROTTLE_MAX_DELAY = 15
AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
AUTOTHROTTLE_DEBUG = False

HTTPCACHE_ENABLED = False

FEED_EXPORT_ENCODING = "utf-8"
DUPEFILTER_DEBUG = True

SCRAPEOPS_NUM_RESULTS = 100
SCRAPEOPS_API_KEY = os.getenv("SCRAPEOPS_API_KEY")

DB_HOST = os.getenv("DB_HOST")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

#LOG_LEVEL = 'WARNING'
#LOG_FILE = "scrapy_errors.log"